{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from build_dataset import create_dataloader\n",
    "from main import get_args\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "from glob import glob\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(True)\n",
    "args.yaml_file = '../config/captioning_config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.add_special_tokens({'cls_token':'[CLS]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 2\n",
    "args.num_workers = 4\n",
    "args.use_saved_frame = False\n",
    "\n",
    "trainloader = create_dataloader(args, 'train', tokenizer)\n",
    "validloader = create_dataloader(args, 'val', tokenizer)\n",
    "testloader = create_dataloader(args, 'test', tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 비디오 존재 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataloader(dataloader):\n",
    "    data_video_info = dataloader.dataset.video_info\n",
    "\n",
    "    error_data_video_ids = []\n",
    "    for i in range(len(data_video_info)):\n",
    "        if not os.path.isfile(data_video_info.iloc[i]['video_path']):\n",
    "            error_data_video_ids.append(data_video_info.iloc[i]['video_id'])\n",
    "        \n",
    "    return error_data_video_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train_video_ids = check_dataloader(trainloader)\n",
    "error_valid_video_ids = check_dataloader(validloader)\n",
    "error_test_video_ids = check_dataloader(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. opencv 문제확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_capture(dataloader):\n",
    "    error_i = []\n",
    "    for i in range(len(dataloader.dataset.video_info)):\n",
    "        try:\n",
    "            print(i, end='\\r')\n",
    "            # read video\n",
    "            cap = cv2.VideoCapture(dataloader.dataset.video_info.iloc[i]['video_path'])\n",
    "\n",
    "            # extract time list of video\n",
    "            time_list = dataloader.dataset.extract_time_list(cap)\n",
    "        except:\n",
    "            error_i.append(i)\n",
    "    \n",
    "    return error_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8267\r"
     ]
    }
   ],
   "source": [
    "train_error_i = check_capture(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080\r"
     ]
    }
   ],
   "source": [
    "val_error_i = check_capture(validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2081\r"
     ]
    }
   ],
   "source": [
    "test_error_i = check_capture(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_error_i):  0\n",
      "len(valid_error_i):  0\n",
      "len(test_error_i):  0\n"
     ]
    }
   ],
   "source": [
    "print('len(train_error_i): ',len(train_error_i))\n",
    "print('len(valid_error_i): ',len(val_error_i))\n",
    "print('len(test_error_i): ',len(test_error_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 비디오 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del trainloader.dataset.annotation['CcPrDDRuHrg']\n",
    "# del trainloader.dataset.annotation['kvaefb9jAHE']\n",
    "\n",
    "# json.dump(trainloader.dataset.annotation,\n",
    "#           open('../datasets/annotations/trainset_highest_f1_removed2video0520.json','w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 2\n",
    "args.num_workers = 4\n",
    "args.use_saved_frame = False\n",
    "trainloader = create_dataloader(args, 'train', tokenizer, test_mode=True)\n",
    "validloader = create_dataloader(args, 'val', tokenizer, test_mode=True)\n",
    "testloader = create_dataloader(args, 'test', tokenizer, test_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_frames(dataloader, split, frames_dir):\n",
    "    frames_dir = os.path.join(frames_dir, split)\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "    \n",
    "    error_boundary_id = []\n",
    "    boundary_list = dataloader.dataset.boundary_list\n",
    "    saved_list = os.listdir(frames_dir)\n",
    "    \n",
    "    for idx, boundary_i in enumerate(boundary_list):\n",
    "        print(f'{idx+1} / {len(boundary_list)}',end='\\r')\n",
    "        boundary_id = boundary_i['boundary_id']\n",
    "        if f'{boundary_id}.pt' in saved_list:\n",
    "            continue \n",
    "    \n",
    "        try:\n",
    "            if not f'{boundary_id}.pt' in os.listdir(frames_dir):\n",
    "                torch.save(\n",
    "                    dict([dataloader.dataset[idx]]),\n",
    "                    os.path.join(frames_dir, f'{boundary_id}.pt')\n",
    "                )\n",
    "        except:\n",
    "            error_boundary_id.append(boundary_id)\n",
    "        \n",
    "    return error_boundary_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26623 / 26623\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_dir = '/datasets/GEBC/frames'\n",
    "save_frames(trainloader, 'train', frames_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6748 / 6748\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_dir = '/datasets/GEBC/frames'\n",
    "\n",
    "save_frames(validloader, 'val', frames_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6619 / 6619\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames_dir = '/datasets/GEBC/frames'\n",
    "\n",
    "save_frames(testloader, 'test', frames_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_b):  26623\n",
      "len(val_b):  6748\n",
      "len(test_b):  6619\n"
     ]
    }
   ],
   "source": [
    "train_b = [f\"{b['boundary_id']}.pt\" for b in trainloader.dataset.boundary_list]\n",
    "val_b = [f\"{b['boundary_id']}.pt\" for b in validloader.dataset.boundary_list]\n",
    "test_b = [f\"{b['boundary_id']}.pt\" for b in testloader.dataset.boundary_list]\n",
    "\n",
    "print('len(train_b): ',len(train_b))\n",
    "print('len(val_b): ',len(val_b))\n",
    "print('len(test_b): ',len(test_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_save):  26623\n",
      "len(val_save):  6748\n",
      "len(test_save):  6619\n"
     ]
    }
   ],
   "source": [
    "frames_dir = '/datasets/GEBC/frames'\n",
    "train_save = os.listdir(os.path.join(frames_dir,'train'))\n",
    "val_save = os.listdir(os.path.join(frames_dir,'val'))\n",
    "test_save = os.listdir(os.path.join(frames_dir,'test'))\n",
    "\n",
    "print('len(train_save): ',len(train_save))\n",
    "print('len(val_save): ',len(val_save))\n",
    "print('len(test_save): ',len(test_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(train_save) - set(train_b):  set()\n",
      "set(train_b) - set(train_save):  set()\n",
      "set(val_save) - set(val_b):  set()\n",
      "set(val_b) - set(val_save):  set()\n",
      "set(test_save) - set(test_b):  set()\n",
      "set(test_b) - set(test_save):  set()\n"
     ]
    }
   ],
   "source": [
    "print('set(train_save) - set(train_b): ',set(train_save) - set(train_b))\n",
    "print('set(train_b) - set(train_save): ',set(train_b) - set(train_save))\n",
    "print('set(val_save) - set(val_b): ',set(val_save) - set(val_b))\n",
    "print('set(val_b) - set(val_save): ',set(val_b) - set(val_save))\n",
    "print('set(test_save) - set(test_b): ',set(test_save) - set(test_b))\n",
    "print('set(test_b) - set(test_save): ',set(test_b) - set(test_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch_size = 2\n",
    "args.num_workers = 4\n",
    "args.use_saved_frame = True\n",
    "trainloader = create_dataloader(args, 'train', tokenizer, test_mode=False)\n",
    "validloader = create_dataloader(args, 'val', tokenizer, test_mode=False)\n",
    "testloader = create_dataloader(args, 'test', tokenizer, test_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_id, captions, frames, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boundary.size(): torch.Size([2, 3, 224, 224])\n",
      "before.size(): torch.Size([2, 10, 3, 224, 224])\n",
      "after.size(): torch.Size([2, 10, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for k in frames.keys():\n",
    "    print(f'{k}.size(): {frames[k].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from IPython.display import Image as Img\n",
    "from IPython.display import display\n",
    "def generate_gif(img_list):    \n",
    "    images = [Image.fromarray(x) for x in img_list]\n",
    "\n",
    "    im = images[0]\n",
    "    im.save('out.gif', save_all=True, append_images=images[1:],loop=0xff, duration=500)\n",
    "    # loop 반복 횟수\n",
    "    # duration 프레임 전환 속도 (500 = 0.5초)\n",
    "    return Img(url='out.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: girl in blue and white bodysuit //Status_Before: jumping on the sponge //Status_After: jump and back flip on the sponge<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|> [CLS]'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(captions['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.cat([\n",
    "    frames['before'][0], \n",
    "    frames['boundary'][0:1], \n",
    "    frames['after'][0]\n",
    "]).permute(0,2,3,1).numpy()\n",
    "\n",
    "imgs = [((img - img.min()) / (img.max() - img.min())*255).astype(np.uint8) for img in imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"out.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_gif(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
